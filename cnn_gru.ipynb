{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'D:/python_project/hyunmin_project/운동동작분류/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import random \n",
    "import time\n",
    "from scipy import fftpack\n",
    "\n",
    "train=pd.read_csv(path + 'open/train_features.csv')\n",
    "train_label=pd.read_csv(path + 'open/train_labels.csv')\n",
    "test=pd.read_csv(path + 'open/test_features.csv')\n",
    "submission=pd.read_csv(path + 'open/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26번을 제외한 id 리스트\n",
    "feature = list(train_label[train_label['label'] != 26]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1875000/1875000 [09:04<00:00, 3446.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# train 데이터에서 26번을 삭제시킨다.\n",
    "temp = []\n",
    "for n in tqdm(range(train.shape[0])):\n",
    "    if train['id'][n] in feature:\n",
    "        temp.append(train.iloc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206087</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.591608</td>\n",
       "      <td>-30.549010</td>\n",
       "      <td>-31.676112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>-0.198974</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>-39.139103</td>\n",
       "      <td>-24.927216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>-0.195114</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>-3.617278</td>\n",
       "      <td>-44.122565</td>\n",
       "      <td>-25.019629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>-0.230366</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>2.712986</td>\n",
       "      <td>-53.597843</td>\n",
       "      <td>-27.454013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.300887</td>\n",
       "      <td>-0.187757</td>\n",
       "      <td>-0.222523</td>\n",
       "      <td>4.286707</td>\n",
       "      <td>-57.906561</td>\n",
       "      <td>-27.961234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964195</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>-0.712530</td>\n",
       "      <td>-0.658357</td>\n",
       "      <td>0.293707</td>\n",
       "      <td>-29.367857</td>\n",
       "      <td>-104.013664</td>\n",
       "      <td>-76.290437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964196</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>-0.683037</td>\n",
       "      <td>-0.658466</td>\n",
       "      <td>0.329223</td>\n",
       "      <td>-30.149089</td>\n",
       "      <td>-101.796809</td>\n",
       "      <td>-76.625087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964197</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>-0.664730</td>\n",
       "      <td>-0.666625</td>\n",
       "      <td>0.364114</td>\n",
       "      <td>-27.873095</td>\n",
       "      <td>-98.776072</td>\n",
       "      <td>-79.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964198</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>-0.630534</td>\n",
       "      <td>-0.682565</td>\n",
       "      <td>0.373696</td>\n",
       "      <td>-23.636550</td>\n",
       "      <td>-99.139495</td>\n",
       "      <td>-80.259478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964199</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>-0.578351</td>\n",
       "      <td>-0.700235</td>\n",
       "      <td>0.384390</td>\n",
       "      <td>-17.917626</td>\n",
       "      <td>-100.181873</td>\n",
       "      <td>-80.676229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  time     acc_x     acc_y     acc_z       gy_x        gy_y  \\\n",
       "0          0     0  1.206087 -0.179371 -0.148447  -0.591608  -30.549010   \n",
       "1          0     1  1.287696 -0.198974 -0.182444   0.303100  -39.139103   \n",
       "2          0     2  1.304609 -0.195114 -0.253382  -3.617278  -44.122565   \n",
       "3          0     3  1.293095 -0.230366 -0.215210   2.712986  -53.597843   \n",
       "4          0     4  1.300887 -0.187757 -0.222523   4.286707  -57.906561   \n",
       "...      ...   ...       ...       ...       ...        ...         ...   \n",
       "964195  3124   595 -0.712530 -0.658357  0.293707 -29.367857 -104.013664   \n",
       "964196  3124   596 -0.683037 -0.658466  0.329223 -30.149089 -101.796809   \n",
       "964197  3124   597 -0.664730 -0.666625  0.364114 -27.873095  -98.776072   \n",
       "964198  3124   598 -0.630534 -0.682565  0.373696 -23.636550  -99.139495   \n",
       "964199  3124   599 -0.578351 -0.700235  0.384390 -17.917626 -100.181873   \n",
       "\n",
       "             gy_z  \n",
       "0      -31.676112  \n",
       "1      -24.927216  \n",
       "2      -25.019629  \n",
       "3      -27.454013  \n",
       "4      -27.961234  \n",
       "...           ...  \n",
       "964195 -76.290437  \n",
       "964196 -76.625087  \n",
       "964197 -79.365125  \n",
       "964198 -80.259478  \n",
       "964199 -80.676229  \n",
       "\n",
       "[964200 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 26번을 삭제시킨 데이터프레임\n",
    "without = pd.DataFrame(data=np.array(temp), columns=train.columns)\n",
    "without = without.astype({'id':int, 'time':int})\n",
    "without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'without' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1b6b1ce8f5ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwithout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./without.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'without' is not defined"
     ]
    }
   ],
   "source": [
    "without.to_csv('./without.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206087</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.591608</td>\n",
       "      <td>-30.549010</td>\n",
       "      <td>-31.676112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>-0.198974</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>-39.139103</td>\n",
       "      <td>-24.927216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>-0.195114</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>-3.617278</td>\n",
       "      <td>-44.122565</td>\n",
       "      <td>-25.019629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>-0.230366</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>2.712986</td>\n",
       "      <td>-53.597843</td>\n",
       "      <td>-27.454013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.300887</td>\n",
       "      <td>-0.187757</td>\n",
       "      <td>-0.222523</td>\n",
       "      <td>4.286707</td>\n",
       "      <td>-57.906561</td>\n",
       "      <td>-27.961234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964195</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>-0.712530</td>\n",
       "      <td>-0.658357</td>\n",
       "      <td>0.293707</td>\n",
       "      <td>-29.367857</td>\n",
       "      <td>-104.013664</td>\n",
       "      <td>-76.290437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964196</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>-0.683037</td>\n",
       "      <td>-0.658466</td>\n",
       "      <td>0.329223</td>\n",
       "      <td>-30.149089</td>\n",
       "      <td>-101.796809</td>\n",
       "      <td>-76.625087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964197</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>-0.664730</td>\n",
       "      <td>-0.666625</td>\n",
       "      <td>0.364114</td>\n",
       "      <td>-27.873095</td>\n",
       "      <td>-98.776072</td>\n",
       "      <td>-79.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964198</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>-0.630534</td>\n",
       "      <td>-0.682565</td>\n",
       "      <td>0.373696</td>\n",
       "      <td>-23.636550</td>\n",
       "      <td>-99.139495</td>\n",
       "      <td>-80.259478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964199</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>-0.578351</td>\n",
       "      <td>-0.700235</td>\n",
       "      <td>0.384390</td>\n",
       "      <td>-17.917626</td>\n",
       "      <td>-100.181873</td>\n",
       "      <td>-80.676229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  time     acc_x     acc_y     acc_z       gy_x        gy_y  \\\n",
       "0          0     0  1.206087 -0.179371 -0.148447  -0.591608  -30.549010   \n",
       "1          0     1  1.287696 -0.198974 -0.182444   0.303100  -39.139103   \n",
       "2          0     2  1.304609 -0.195114 -0.253382  -3.617278  -44.122565   \n",
       "3          0     3  1.293095 -0.230366 -0.215210   2.712986  -53.597843   \n",
       "4          0     4  1.300887 -0.187757 -0.222523   4.286707  -57.906561   \n",
       "...      ...   ...       ...       ...       ...        ...         ...   \n",
       "964195  3124   595 -0.712530 -0.658357  0.293707 -29.367857 -104.013664   \n",
       "964196  3124   596 -0.683037 -0.658466  0.329223 -30.149089 -101.796809   \n",
       "964197  3124   597 -0.664730 -0.666625  0.364114 -27.873095  -98.776072   \n",
       "964198  3124   598 -0.630534 -0.682565  0.373696 -23.636550  -99.139495   \n",
       "964199  3124   599 -0.578351 -0.700235  0.384390 -17.917626 -100.181873   \n",
       "\n",
       "             gy_z  \n",
       "0      -31.676112  \n",
       "1      -24.927216  \n",
       "2      -25.019629  \n",
       "3      -27.454013  \n",
       "4      -27.961234  \n",
       "...           ...  \n",
       "964195 -76.290437  \n",
       "964196 -76.625087  \n",
       "964197 -79.365125  \n",
       "964198 -80.259478  \n",
       "964199 -80.676229  \n",
       "\n",
       "[964200 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without = pd.read_csv('./without.csv', index_col=0)\n",
    "without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1607/1607 [00:02<00:00, 589.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://dacon.io/competitions/official/235689/codeshare/2347?page=1&dtype=recent&ptype=pub\n",
    "# 데이터 증강을 통해 과접합을 줄여보자 - DACON\n",
    "# 증강할 데이터 정리\n",
    "\n",
    "without_train = []\n",
    "\n",
    "for uid in tqdm(without['id'].unique()):\n",
    "    temp = np.array(without[without['id'] == uid].iloc[:,2:], np.float32).T\n",
    "    without_train.append(temp)\n",
    "\n",
    "without_train = np.array(without_train, np.float32)\n",
    "without_train = without_train[:,:,:,np.newaxis].reshape(-1,600,6)\n",
    "\n",
    "without_label = train_label[train_label['label'] != 26]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 3125/3125 [00:09<00:00, 338.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 782/782 [00:00<00:00, 917.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://dacon.io/competitions/official/235689/codeshare/2347?page=1&dtype=recent&ptype=pub\n",
    "# 데이터 증강을 통해 과접합을 줄여보자 - DACON\n",
    "# 원본 데이터 정리\n",
    "import tensorflow as tf\n",
    "\n",
    "x_train = []\n",
    "\n",
    "for uid in tqdm(train['id'].unique()):\n",
    "    temp = np.array(train[train['id'] == uid].iloc[:,2:], np.float32).T\n",
    "    x_train.append(temp)\n",
    "\n",
    "x_train = np.array(x_train, np.float32)\n",
    "x_train = x_train[:,:,:,np.newaxis].reshape(-1,600,6)\n",
    "\n",
    "y_train = train_label['label']\n",
    "y_categorical = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "x_test = []\n",
    "\n",
    "for uid in tqdm(test['id'].unique()):\n",
    "    temp = np.array(test[test['id'] == uid].iloc[:,2:], np.float32).T\n",
    "    x_test.append(temp)\n",
    "\n",
    "x_test = np.array(x_test, np.float32)\n",
    "x_test = x_test[:,:,:,np.newaxis].reshape(-1,600,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 61.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 61.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 61.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 61.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 56.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 65.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def aug(data, shift):\n",
    "    shift_data = np.roll(data, shift, axis=2)\n",
    "    return shift_data\n",
    "\n",
    "# 데이터 증강\n",
    "shift_data = []\n",
    "shift_label = []\n",
    "for n in tqdm(range(5)):\n",
    "    shifted = aug(without_train, int(random.random() * 1000))\n",
    "    shift_data.append(shifted)\n",
    "    shift_label.append(without_label)\n",
    "\n",
    "for n in tqdm(range(5)):\n",
    "    shifted = aug(without_train, int(random.random() * 900))\n",
    "    shift_data.append(shifted)\n",
    "    shift_label.append(without_label)\n",
    "\n",
    "for n in tqdm(range(5)):\n",
    "    shifted = aug(without_train, int(random.random() * 700))\n",
    "    shift_data.append(shifted)\n",
    "    shift_label.append(without_label)\n",
    "    \n",
    "for n in tqdm(range(5)):\n",
    "    shifted = aug(without_train, int(random.random() * 500))\n",
    "    shift_data.append(shifted)\n",
    "    shift_label.append(without_label)\n",
    "    \n",
    "for n in tqdm(range(5)):\n",
    "    shifted = aug(without_train, int(random.random() * 300))\n",
    "    shift_data.append(shifted)\n",
    "    shift_label.append(without_label)\n",
    "    \n",
    "for n in tqdm(range(5)):\n",
    "    shifted = aug(without_train, int(n * 100))\n",
    "    shift_data.append(shifted)\n",
    "    shift_label.append(without_label)\n",
    "    \n",
    "\n",
    "shift_data = np.array(shift_data).reshape(-1,600,6)\n",
    "shift_label = np.array(shift_label).reshape(-1,1)\n",
    "shift_categorical = tf.keras.utils.to_categorical(shift_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51335, 600, 6)\n",
      "(51335, 61)\n"
     ]
    }
   ],
   "source": [
    "# 원본 데이터와 증강 데이터 합치기\n",
    "concat_train = np.concatenate((x_train, shift_data), axis=0)\n",
    "concat_label = np.concatenate((y_categorical, shift_categorical), axis=0)\n",
    "print(concat_train.shape)\n",
    "print(concat_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.206087</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>1.300887</td>\n",
       "      <td>1.289304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.281405</td>\n",
       "      <td>1.242273</td>\n",
       "      <td>1.198871</td>\n",
       "      <td>1.113677</td>\n",
       "      <td>1.192241</td>\n",
       "      <td>1.230094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.175210</td>\n",
       "      <td>1.170251</td>\n",
       "      <td>1.075277</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.956588</td>\n",
       "      <td>0.977357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997987</td>\n",
       "      <td>0.914106</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.790079</td>\n",
       "      <td>0.759773</td>\n",
       "      <td>0.736777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721108</td>\n",
       "      <td>0.702457</td>\n",
       "      <td>0.699058</td>\n",
       "      <td>0.623462</td>\n",
       "      <td>0.654510</td>\n",
       "      <td>0.682234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x     acc_y     acc_z      gy_x      gy_y      gy_z\n",
       "0  1.206087  1.287696  1.304609  1.293095  1.300887  1.289304\n",
       "1  1.281405  1.242273  1.198871  1.113677  1.192241  1.230094\n",
       "2  1.175210  1.170251  1.075277  0.993865  0.956588  0.977357\n",
       "3  0.997987  0.914106  0.851735  0.790079  0.759773  0.736777\n",
       "4  0.721108  0.702457  0.699058  0.623462  0.654510  0.682234"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_train = pd.DataFrame(np.concatenate(concat_train))\n",
    "\n",
    "concat_train.columns = ['acc_x', 'acc_y', 'acc_z', 'gy_x', 'gy_y', 'gy_z']\n",
    "concat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.628100</td>\n",
       "      <td>-0.462548</td>\n",
       "      <td>-0.363481</td>\n",
       "      <td>-0.351750</td>\n",
       "      <td>-0.312934</td>\n",
       "      <td>-0.275446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.375200</td>\n",
       "      <td>-0.457493</td>\n",
       "      <td>-0.594858</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.717086</td>\n",
       "      <td>-0.770898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.846592</td>\n",
       "      <td>-0.913577</td>\n",
       "      <td>-0.976689</td>\n",
       "      <td>-1.025751</td>\n",
       "      <td>-1.008726</td>\n",
       "      <td>-1.053743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.122112</td>\n",
       "      <td>-1.121161</td>\n",
       "      <td>-1.091729</td>\n",
       "      <td>-1.044890</td>\n",
       "      <td>-0.966640</td>\n",
       "      <td>-0.955708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.896795</td>\n",
       "      <td>-0.827592</td>\n",
       "      <td>-0.691637</td>\n",
       "      <td>-0.698677</td>\n",
       "      <td>-0.605324</td>\n",
       "      <td>-0.539302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x     acc_y     acc_z      gy_x      gy_y      gy_z\n",
       "0 -0.628100 -0.462548 -0.363481 -0.351750 -0.312934 -0.275446\n",
       "1 -0.375200 -0.457493 -0.594858 -0.606624 -0.717086 -0.770898\n",
       "2 -0.846592 -0.913577 -0.976689 -1.025751 -1.008726 -1.053743\n",
       "3 -1.122112 -1.121161 -1.091729 -1.044890 -0.966640 -0.955708\n",
       "4 -0.896795 -0.827592 -0.691637 -0.698677 -0.605324 -0.539302"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = pd.DataFrame(np.concatenate(x_test))\n",
    "\n",
    "x_test.columns = ['acc_x', 'acc_y', 'acc_z', 'gy_x', 'gy_y', 'gy_z']\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-548dcf5ad7a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconcat_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FFT_acc_y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mconcat_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FFT_acc_t'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_t'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_t'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_z'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FFT_acc_x'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FFT_acc_y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "concat_train['acc_t']  = concat_train.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 +  x['acc_z'] **2)**(1/3), axis=1)\n",
    "concat_train['FFT_acc_x'] = sp.fftpack.fft(np.array(concat_train['acc_x']))\n",
    "concat_train['FFT_acc_y'] = sp.fftpack.fft(np.array(concat_train['acc_y']))\n",
    "concat_train['FFT_acc_t'] = sp.fftpack.fft(np.array(concat_train['acc_t']))\n",
    "x_test['acc_t']  = x_test.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 +  x['acc_z'] **2)**(1/3), axis=1)\n",
    "x_test['FFT_acc_x'] = sp.fftpack.fft(np.array(x_test['acc_x']))\n",
    "x_test['FFT_acc_y'] = sp.fftpack.fft(np.array(x_test['acc_y']))\n",
    "x_test['FFT_acc_t'] = sp.fftpack.fft(np.array(x_test['acc_t']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = concat_train\n",
    "y = concat_label\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tf.reshape(np.array(train.iloc[:,2:]), [-1,600,6]) \n",
    "# X = np.asarray(X) \n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_label['label'].values \n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b = True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        \n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        \n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    \n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation = 'relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training = training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "\n",
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, \n",
    "                 maximum_position_encoding, rate = 0.1):\n",
    "        \n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.dff = dff\n",
    "        self.maximum_position_encoding = maximum_position_encoding\n",
    "        self.rate = rate\n",
    "\n",
    "#         self.pos_encoding = positional_encoding(self.maximum_position_encoding, \n",
    "#                                                 self.d_model)\n",
    "#         self.embedding = tf.keras.layers.Dense(self.d_model)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim = self.maximum_position_encoding, \n",
    "                                                 output_dim = self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(self.d_model, self.num_heads, self.dff, self.rate) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(self.rate)\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_layers': self.num_layers,\n",
    "            'd_model': self.d_model,\n",
    "            'num_heads': self.num_heads,\n",
    "            'dff': self.dff,\n",
    "            'maximum_position_encoding': self.maximum_position_encoding,\n",
    "            'dropout': self.dropout,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x, training, mask = None):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "#         x += self.pos_encoding[:, :seq_len, :]\n",
    "#         x = self.embedding(x)\n",
    "        positions = tf.range(start = 0, limit = seq_len, delta = 1)\n",
    "        x += self.pos_emb(positions)\n",
    "\n",
    "        x = self.dropout(x, training = training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_multi_head import MultiHead\n",
    "def attention():  \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(MultiHead([\n",
    "        Conv1D(input_shape=(600,6), filters=32, kernel_size=3, padding='same', name='Conv1'),\n",
    "        Conv1D(input_shape=(600,6), filters=32, kernel_size=5, padding='same', name='Conv2'),\n",
    "        Conv1D(input_shape=(600,6), filters=32, kernel_size=7,padding='same', name='Conv3'),\n",
    "    ], name='Multi-Head-Attention'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MultiHead([\n",
    "        Conv1D(input_shape=(600,6), filters=64, kernel_size=3, padding='same', name='Conv4'),\n",
    "        Conv1D(input_shape=(600,6), filters=64, kernel_size=5, padding='same', name='Conv5'),\n",
    "        Conv1D(input_shape=(600,6), filters=64, kernel_size=7,padding='same', name='Conv6'),\n",
    "    ], name='Multi-Head-Attention2'))\n",
    "    model.add(keras.layers.Flatten(name='Flatten'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=61, activation='softmax', name='Dense'))\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention import Attention\n",
    "def build_model():  \n",
    "    model= Sequential()\n",
    "    model.add(Conv1D(64, input_shape=(600,6), kernel_size=3, padding='same',activation='relu'))\n",
    "    model.add(Conv1D(64, kernel_size=3,padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv1D(128,kernel_size=3,padding='same',activation='relu'))\n",
    "    model.add(Conv1D(128,kernel_size=3,padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv1D(256,kernel_size=3,padding='same',activation='relu'))\n",
    "    model.add(Conv1D(256,kernel_size=3,padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv1D(512,kernel_size=3,padding='same',activation='relu'))\n",
    "    model.add(Conv1D(512,kernel_size=3,padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Dropout(0.4))\n",
    "    #model.add(GlobalAveragePooling1D())\n",
    "    #model.add(TimeDistributed(Flatten(), name='Flatten'))\n",
    "    #model.add(Bidirectional(GRU(units=32, name='Bi-GRU')))\n",
    "    #model.add(GRU(64,return_sequences=True))\n",
    "    #model.add(Dropout(0.4))\n",
    "    \n",
    "    #model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128,\n",
    "    #                                                   return_sequences=True)))\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Attention())\n",
    "    \n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(61, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusals\\anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True, random_state=42 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Validating on fold 1 ...\n",
      "... Training ...\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kfold = StratifiedKFold(n_splits = 5, random_state = 960418, shuffle = True)\n",
    "for idx,(train_idx, val_idx) in enumerate(mskf.split(X,y)):   \n",
    "    print(\"... Validating on fold {} ...\".format(idx+1)) \n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx] \n",
    "    \n",
    "    ##### augment data #####\n",
    "#     print(\"... Augmenting Data ...\")\n",
    "#     X_augmented = [] \n",
    "#     y_augmented = [] \n",
    "#     for i in tqdm(range(X_train.shape[0])): \n",
    "#         for j in range(20): \n",
    "#             shifted = np.roll(X_train[i], int(random.random() * 700)) \n",
    "#             X_augmented.append(shifted) \n",
    "#             y_augmented.append(y_train[i]) \n",
    "#     X_augmented = np.asarray(X_augmented) \n",
    "#     y_augmented = np.asarray(y_augmented)\n",
    "#     X_train = np.concatenate([X_train, X_augmented]) \n",
    "#     y_train = np.concatenate([y_train, y_augmented])\n",
    "    \n",
    "    \n",
    "    ###### feature engineering data ##### \n",
    "#     print(\"... Feature Engineering ...\")\n",
    "#     X_fourier_real = [] \n",
    "#     X_fourier_imag = [] \n",
    "#     for i in tqdm(range(X_train.shape[0]), position = 0, leave = True):  \n",
    "#         real_part = np.fft.fft(X_train[i]).real \n",
    "#         imag_part = np.fft.fft(X_train[i]).imag \n",
    "\n",
    "#         X_fourier_real.append(real_part)\n",
    "#         X_fourier_imag.append(imag_part) \n",
    "    \n",
    "#     X_fourier_real = np.asarray(X_fourier_real)  \n",
    "#     X_fourier_imag = np.asarray(X_fourier_imag)\n",
    "#     X_train = np.concatenate([X_train, X_fourier_real, X_fourier_imag], axis = 2)   \n",
    "    \n",
    "    \n",
    "#     X_val_fourier_real = [] \n",
    "#     X_val_fourier_imag = [] \n",
    "#     for i in tqdm(range(X_val.shape[0]), position = 0, leave = True):\n",
    "#         real_part = np.fft.fft(X_val[i]).real \n",
    "#         imag_part = np.fft.fft(X_val[i]).imag \n",
    "#         X_val_fourier_real.append(real_part) \n",
    "#         X_val_fourier_imag.append(imag_part)\n",
    "    \n",
    "#     X_val_fourier_real = np.asarray(X_val_fourier_real) \n",
    "#     X_val_fourier_imag = np.asarray(X_val_fourier_imag)\n",
    "#     X_val = np.concatenate([X_val, X_val_fourier_real, X_val_fourier_imag], axis = 2)\n",
    "        \n",
    "    \n",
    "    ##### train model #####  \n",
    "    print(\"... Training ...\") \n",
    "    model = attention() \n",
    "    model_path = './kfold/' + str(idx+1) + 'epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
    "    #learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.8)\n",
    "    checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5) \n",
    "\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              epochs = 200,\n",
    "              batch_size = 32,\n",
    "              validation_data = (X_val, y_val),\n",
    "              callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "gru1 = load_model('./kfold/1epoch_045_val_0.011.h5')\n",
    "gru2 = load_model('./kfold/2epoch_040_val_0.013.h5') \n",
    "gru3 = load_model('./kfold/3epoch_041_val_0.015.h5')  \n",
    "gru4 = load_model('./kfold/4epoch_041_val_0.014.h5') \n",
    "gru5 = load_model('./kfold/5epoch_066_val_0.008.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = gru1.predict(x_test) \n",
    "pred2 = gru2.predict(x_test)\n",
    "pred3 = gru3.predict(x_test) \n",
    "pred4 = gru4.predict(x_test) \n",
    "pred5 = gru5.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_avg = (pred1 + pred2 + pred3 + pred4 + pred5)/5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:,1:] = pred_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>4.151162e-15</td>\n",
       "      <td>3.458583e-21</td>\n",
       "      <td>1.837691e-21</td>\n",
       "      <td>4.706263e-19</td>\n",
       "      <td>1.641891e-07</td>\n",
       "      <td>1.904628e-22</td>\n",
       "      <td>1.324257e-18</td>\n",
       "      <td>4.950554e-18</td>\n",
       "      <td>4.019481e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>2.062765e-07</td>\n",
       "      <td>3.987792e-11</td>\n",
       "      <td>9.807912e-10</td>\n",
       "      <td>1.588842e-24</td>\n",
       "      <td>1.349132e-21</td>\n",
       "      <td>3.701916e-34</td>\n",
       "      <td>2.429907e-14</td>\n",
       "      <td>5.947187e-01</td>\n",
       "      <td>2.717999e-30</td>\n",
       "      <td>1.880695e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>4.060099e-06</td>\n",
       "      <td>8.223476e-10</td>\n",
       "      <td>1.115528e-10</td>\n",
       "      <td>2.015533e-05</td>\n",
       "      <td>8.942793e-08</td>\n",
       "      <td>1.696470e-04</td>\n",
       "      <td>5.272901e-12</td>\n",
       "      <td>6.910622e-06</td>\n",
       "      <td>6.445728e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>9.043380e-07</td>\n",
       "      <td>3.344014e-09</td>\n",
       "      <td>5.665017e-11</td>\n",
       "      <td>3.160349e-09</td>\n",
       "      <td>7.622304e-11</td>\n",
       "      <td>1.712188e-10</td>\n",
       "      <td>2.005292e-03</td>\n",
       "      <td>2.268102e-12</td>\n",
       "      <td>1.559114e-11</td>\n",
       "      <td>4.736424e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>8.407600e-08</td>\n",
       "      <td>3.418907e-05</td>\n",
       "      <td>9.069059e-17</td>\n",
       "      <td>3.699610e-12</td>\n",
       "      <td>1.155622e-24</td>\n",
       "      <td>4.325111e-21</td>\n",
       "      <td>2.142217e-05</td>\n",
       "      <td>1.962011e-11</td>\n",
       "      <td>1.874574e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>3.352589e-24</td>\n",
       "      <td>8.941564e-35</td>\n",
       "      <td>3.311255e-31</td>\n",
       "      <td>7.366345e-06</td>\n",
       "      <td>3.561864e-22</td>\n",
       "      <td>2.690297e-13</td>\n",
       "      <td>1.158918e-14</td>\n",
       "      <td>2.274473e-26</td>\n",
       "      <td>1.935776e-09</td>\n",
       "      <td>1.112074e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>2.711893e-04</td>\n",
       "      <td>7.834983e-11</td>\n",
       "      <td>5.505019e-12</td>\n",
       "      <td>1.183145e-08</td>\n",
       "      <td>3.976141e-11</td>\n",
       "      <td>1.825397e-04</td>\n",
       "      <td>1.207761e-14</td>\n",
       "      <td>2.449024e-05</td>\n",
       "      <td>4.845005e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.779869e-10</td>\n",
       "      <td>6.297653e-12</td>\n",
       "      <td>4.604476e-17</td>\n",
       "      <td>1.105020e-10</td>\n",
       "      <td>5.210835e-14</td>\n",
       "      <td>7.456736e-10</td>\n",
       "      <td>1.268570e-05</td>\n",
       "      <td>2.131369e-12</td>\n",
       "      <td>1.499115e-12</td>\n",
       "      <td>8.298068e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>1.911167e-02</td>\n",
       "      <td>4.319781e-10</td>\n",
       "      <td>2.526147e-14</td>\n",
       "      <td>1.427498e-08</td>\n",
       "      <td>3.781315e-01</td>\n",
       "      <td>1.455914e-04</td>\n",
       "      <td>1.448823e-15</td>\n",
       "      <td>1.944142e-06</td>\n",
       "      <td>2.627512e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.388366e-07</td>\n",
       "      <td>2.004171e-08</td>\n",
       "      <td>2.910642e-11</td>\n",
       "      <td>4.391534e-12</td>\n",
       "      <td>4.048421e-15</td>\n",
       "      <td>2.114779e-13</td>\n",
       "      <td>1.145833e-04</td>\n",
       "      <td>2.235625e-07</td>\n",
       "      <td>9.088950e-06</td>\n",
       "      <td>1.163529e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id             0             1             2             3             4  \\\n",
       "0  3125  4.151162e-15  3.458583e-21  1.837691e-21  4.706263e-19  1.641891e-07   \n",
       "1  3126  4.060099e-06  8.223476e-10  1.115528e-10  2.015533e-05  8.942793e-08   \n",
       "2  3127  8.407600e-08  3.418907e-05  9.069059e-17  3.699610e-12  1.155622e-24   \n",
       "3  3128  2.711893e-04  7.834983e-11  5.505019e-12  1.183145e-08  3.976141e-11   \n",
       "4  3129  1.911167e-02  4.319781e-10  2.526147e-14  1.427498e-08  3.781315e-01   \n",
       "\n",
       "              5             6             7             8  ...            51  \\\n",
       "0  1.904628e-22  1.324257e-18  4.950554e-18  4.019481e-21  ...  2.062765e-07   \n",
       "1  1.696470e-04  5.272901e-12  6.910622e-06  6.445728e-05  ...  9.043380e-07   \n",
       "2  4.325111e-21  2.142217e-05  1.962011e-11  1.874574e-13  ...  3.352589e-24   \n",
       "3  1.825397e-04  1.207761e-14  2.449024e-05  4.845005e-07  ...  2.779869e-10   \n",
       "4  1.455914e-04  1.448823e-15  1.944142e-06  2.627512e-08  ...  3.388366e-07   \n",
       "\n",
       "             52            53            54            55            56  \\\n",
       "0  3.987792e-11  9.807912e-10  1.588842e-24  1.349132e-21  3.701916e-34   \n",
       "1  3.344014e-09  5.665017e-11  3.160349e-09  7.622304e-11  1.712188e-10   \n",
       "2  8.941564e-35  3.311255e-31  7.366345e-06  3.561864e-22  2.690297e-13   \n",
       "3  6.297653e-12  4.604476e-17  1.105020e-10  5.210835e-14  7.456736e-10   \n",
       "4  2.004171e-08  2.910642e-11  4.391534e-12  4.048421e-15  2.114779e-13   \n",
       "\n",
       "             57            58            59            60  \n",
       "0  2.429907e-14  5.947187e-01  2.717999e-30  1.880695e-09  \n",
       "1  2.005292e-03  2.268102e-12  1.559114e-11  4.736424e-04  \n",
       "2  1.158918e-14  2.274473e-26  1.935776e-09  1.112074e-19  \n",
       "3  1.268570e-05  2.131369e-12  1.499115e-12  8.298068e-08  \n",
       "4  1.145833e-04  2.235625e-07  9.088950e-06  1.163529e-06  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('cnn_5_fold5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
